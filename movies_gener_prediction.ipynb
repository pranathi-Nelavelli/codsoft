{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UX-XqipLi1sP"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import csv\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "def fetch_movies(page_no):\n",
        "    url = f\"https://api.themoviedb.org/3/discover/movie?include_adult=true&include_video=false&language=en&page={page_no}&language=en\"\n",
        "    headers = {\n",
        "        \"accept\": \"application/json\",\n",
        "        \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiIwNDAyNGVlMDE1NTFmMTBmNmM4ZWVlMGFlNzFmMzYwYSIsInN1YiI6IjY0YmY1ZDUxNmQ0Yzk3MDBhZDU0ZTNhNiIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.pFe2H3bOTE1Wsv_z12ooKU2pDGYOFiG8AasXPd8nXpM\"\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "    data = response.json()\n",
        "    return data.get(\"results\", [])\n",
        "\n",
        "\n",
        "def write_movies_to_csv(movies,temp = False):\n",
        "    with open(\"movies.csv\", mode=\"a\", encoding=\"utf-8\", newline=\"\") as file:\n",
        "        fieldnames = [\"adult\", \"backdrop_path\", \"genre_ids\", \"id\", \"original_language\",\n",
        "                      \"original_title\", \"overview\", \"popularity\", \"poster_path\", \"release_date\",\n",
        "                      \"title\", \"video\", \"vote_average\", \"vote_count\"]\n",
        "\n",
        "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
        "        if temp:\n",
        "            writer.writeheader()\n",
        "\n",
        "\n",
        "        for movie in movies:\n",
        "            writer.writerow({\n",
        "                \"adult\": movie.get(\"adult\", \"\"),\n",
        "                \"backdrop_path\": movie.get(\"backdrop_path\", \"\"),\n",
        "                \"genre_ids\": \",\".join(str(genre_id) for genre_id in movie.get(\"genre_ids\", [])),\n",
        "                \"id\": movie.get(\"id\", \"\"),\n",
        "                \"original_language\": movie.get(\"original_language\", \"\"),\n",
        "                \"original_title\": movie.get(\"original_title\", \"\"),\n",
        "                \"overview\": movie.get(\"overview\", \"\"),\n",
        "                \"popularity\": movie.get(\"popularity\", \"\"),\n",
        "                \"poster_path\": movie.get(\"poster_path\", \"\"),\n",
        "                \"release_date\": movie.get(\"release_date\", \"\"),\n",
        "                \"title\": movie.get(\"title\", \"\"),\n",
        "                \"video\": movie.get(\"video\", \"\"),\n",
        "                \"vote_average\": movie.get(\"vote_average\", \"\"),\n",
        "                \"vote_count\": movie.get(\"vote_count\", \"\")\n",
        "            })\n",
        "\n",
        "i = 0\n",
        "t = 500\n",
        "\n",
        "pbar = tqdm(total=t, desc=\"Fetching Movies\")\n",
        "\n",
        "for page_no in range(1, t):\n",
        "    if i == 39:\n",
        "        time.sleep(4)\n",
        "        i = 0\n",
        "\n",
        "    movies = fetch_movies(page_no)\n",
        "    if not movies:\n",
        "        break\n",
        "    if page_no == 1:\n",
        "        write_movies_to_csv(movies, True)\n",
        "    else:\n",
        "        write_movies_to_csv(movies)\n",
        "    i += 1\n",
        "\n",
        "    pbar.update(1)\n",
        "\n",
        "pbar.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XSC4YGhnZZZ3"
      },
      "outputs": [],
      "source": [
        "def ret_genre(id):\n",
        "    url = \"https://api.themoviedb.org/3/genre/movie/list?language=en\"\n",
        "\n",
        "    headers = {\n",
        "        \"accept\": \"application/json\",\n",
        "        \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiIwNDAyNGVlMDE1NTFmMTBmNmM4ZWVlMGFlNzFmMzYwYSIsInN1YiI6IjY0YmY1ZDUxNmQ0Yzk3MDBhZDU0ZTNhNiIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.pFe2H3bOTE1Wsv_z12ooKU2pDGYOFiG8AasXPd8nXpM\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "\n",
        "    data_dict = json.loads(response.text)\n",
        "    genre_dict = {genre['id']: genre['name'] for genre in data_dict['genres']}\n",
        "\n",
        "    return genre_dict[id]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iDxrKBSsnDD",
        "outputId": "b205b481-d3e1-41b5-8a8a-dd8791ad192d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 genre_ids                                title  \\\n",
            "0     16,35,10751,14,10749                            Elemental   \n",
            "1                    53,28                       Heart of Stone   \n",
            "2                 16,28,12  Spider-Man: Across the Spider-Verse   \n",
            "3                28,12,878     Transformers: Rise of the Beasts   \n",
            "4                 35,12,14                               Barbie   \n",
            "...                    ...                                  ...   \n",
            "9973           18,35,10749                          About a Boy   \n",
            "9975                    35                     Kindergarten Cop   \n",
            "9976           10402,10770     The Weeknd: Live at SoFi Stadium   \n",
            "9978             878,35,18        Landscape with Invisible Hand   \n",
            "9979                 12,18                          On the Road   \n",
            "\n",
            "                                               overview  \n",
            "0     In a city where fire, water, land and air resi...  \n",
            "1     An intelligence operative for a shadowy global...  \n",
            "2     After reuniting with Gwen Stacy, Brooklyn’s fu...  \n",
            "3     When a new threat capable of destroying the en...  \n",
            "4     Barbie and Ken are having the time of their li...  \n",
            "...                                                 ...  \n",
            "9973  Will Freeman is a good-looking, smooth-talking...  \n",
            "9975  Hard-edged cop John Kimble gets more than he b...  \n",
            "9976  Filmed at LA’s SoFi Stadium, The Weeknd brings...  \n",
            "9978  Years into a benevolent alien occupation, mank...  \n",
            "9979  Dean and Sal are the portrait of the Beat Gene...  \n",
            "\n",
            "[7339 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"movies.csv\")\n",
        "df = df[df[\"original_language\"] == \"en\"]\n",
        "df = df[[\"genre_ids\", \"title\", \"overview\"]]\n",
        "df = df.drop_duplicates()\n",
        "df = df.dropna(subset=[\"genre_ids\"])\n",
        "\n",
        "\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_cIQemVG1ID",
        "outputId": "f6f24abd-b30c-4442-f73d-585de6ba96d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqLlBMfIHtfW",
        "outputId": "97489470-78e1-4856-ebef-c4e86fcd7a6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eliminating element ...\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    df[\"overview\"] = df[\"overview\"].apply(lambda x: \" \".join(word_tokenize(x[:50])))\n",
        "\n",
        "\n",
        "    df[\"overview\"] = df[\"overview\"].apply(lambda x: \" \".join(x.split()[:-1]))\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    df[\"overview\"] = df[\"overview\"].apply(lambda x: \" \".join([word for word in x.split() if word.lower() not in stop_words]))\n",
        "\n",
        "except:\n",
        "    print(\"eliminating element ...\")\n",
        "    df = df.dropna(subset=[\"overview\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qteqDkcaHzn1",
        "outputId": "b7f09ddb-e11b-4226-f9cd-b885682fee74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       In a city where fire, water, land and air resi...\n",
            "1       An intelligence operative for a shadowy global...\n",
            "2       After reuniting with Gwen Stacy, Brooklyn’s fu...\n",
            "3       When a new threat capable of destroying the en...\n",
            "4       Barbie and Ken are having the time of their li...\n",
            "                              ...                        \n",
            "9973    Will Freeman is a good-looking, smooth-talking...\n",
            "9975    Hard-edged cop John Kimble gets more than he b...\n",
            "9976    Filmed at LA’s SoFi Stadium, The Weeknd brings...\n",
            "9978    Years into a benevolent alien occupation, mank...\n",
            "9979    Dean and Sal are the portrait of the Beat Gene...\n",
            "Name: overview, Length: 7338, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df['overview'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WBrhJNbqH3y6"
      },
      "outputs": [],
      "source": [
        "df[\"genre_ids\"] = df[\"genre_ids\"].apply(lambda x: int(x.split(\",\")[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxj1NwydJ3nW",
        "outputId": "6309ae35-1051-4218-d5ec-a6a8bf3942e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0          16\n",
            "1          53\n",
            "2          16\n",
            "3          28\n",
            "4          35\n",
            "        ...  \n",
            "9973       18\n",
            "9975       35\n",
            "9976    10402\n",
            "9978      878\n",
            "9979       12\n",
            "Name: genre_ids, Length: 7338, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df[\"genre_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "89AH-48lJ9OQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import pickle\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUCyA_TELMZv",
        "outputId": "03473cb2-43bf-453a-bb21-4c8a36cdd290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Genre ID: 28\n",
            "gener = Action\n"
          ]
        }
      ],
      "source": [
        "X = df[\"overview\"]\n",
        "y = df[\"genre_ids\"]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text data to numerical features using TF-IDF vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the number of features as needed\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Train the logistic regression model\n",
        "LR_overview_genre_model = LogisticRegression(max_iter=1000)\n",
        "LR_overview_genre_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Save the trained model to a pickle file\n",
        "with open(\"LR_overview_gener_model.pkl\", \"wb\") as file:\n",
        "    pickle.dump(LR_overview_genre_model, file)\n",
        "\n",
        "# Use the trained model to predict the genre of an overview\n",
        "overview_to_predict = ('''Over many missions and against impossible odds, Dom Toretto and his family have outsmarted, out-nerved and outdriven every foe in their path. Now, they confront the most lethal opponent they've ever faced: A terrifying threat emerging from the shadows of the past who's fueled by blood revenge, and who is determined to shatter this family and destroy everything—and everyone—that Dom loves, forever.''')\n",
        "overview_to_predict_tfidf = tfidf_vectorizer.transform([overview_to_predict])\n",
        "predicted_genre_id = LR_overview_genre_model.predict(overview_to_predict_tfidf)[0]\n",
        "\n",
        "y_pred = LR_overview_genre_model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Predicted Genre ID:\", predicted_genre_id)\n",
        "print(f\"gener = {ret_genre(predicted_genre_id)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ItlvJWC8LeFv"
      },
      "outputs": [],
      "source": [
        "df[\"title\"] = df[\"title\"].apply(lambda x: \" \".join(word_tokenize(x)))\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "df[\"title\"] = df[\"title\"].apply(lambda x: \" \".join([word for word in x.split() if word.lower() not in stop_words]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eox3jbLPfml",
        "outputId": "014de08c-0997-45b3-ad83-58442e6d1a22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Genre ID: 27\n",
            "gener = Horror\n"
          ]
        }
      ],
      "source": [
        "X = df[\"overview\"]\n",
        "y = df[\"genre_ids\"]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text data to numerical features using TF-IDF vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the number of features as needed\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Train the logistic regression model\n",
        "LR_title_genre_model = LogisticRegression(max_iter=1000)\n",
        "LR_title_genre_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Save the trained model to a pickle file\n",
        "with open(\"LR_title_gener_model.pkl\", \"wb\") as file:\n",
        "    pickle.dump(LR_title_genre_model, file)\n",
        "\n",
        "\n",
        "overview_to_predict = ('''walking dead''')\n",
        "overview_to_predict_tfidf = tfidf_vectorizer.transform([overview_to_predict])\n",
        "predicted_genre_id = LR_title_genre_model.predict(overview_to_predict_tfidf)[0]\n",
        "\n",
        "y_pred = LR_overview_genre_model.predict(X_test_tfidf)\n",
        "\n",
        "\n",
        "print(\"Predicted Genre ID:\", predicted_genre_id)\n",
        "print(f\"gener = {ret_genre(predicted_genre_id)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnCqM3g5Qa65",
        "outputId": "149ba68e-3579-4f85-d596-8512c411ab10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{28: 'Action', 12: 'Adventure', 16: 'Animation', 35: 'Comedy', 80: 'Crime', 99: 'Documentary', 18: 'Drama', 10751: 'Family', 14: 'Fantasy', 36: 'History', 27: 'Horror', 10402: 'Music', 9648: 'Mystery', 10749: 'Romance', 878: 'Science Fiction', 10770: 'TV Movie', 53: 'Thriller', 10752: 'War', 37: 'Western'}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "url = \"https://api.themoviedb.org/3/genre/movie/list?language=en\"\n",
        "\n",
        "headers = {\n",
        "    \"accept\": \"application/json\",\n",
        "    \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiIwNDAyNGVlMDE1NTFmMTBmNmM4ZWVlMGFlNzFmMzYwYSIsInN1YiI6IjY0YmY1ZDUxNmQ0Yzk3MDBhZDU0ZTNhNiIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.pFe2H3bOTE1Wsv_z12ooKU2pDGYOFiG8AasXPd8nXpM\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "\n",
        "data_dict = json.loads(response.text)\n",
        "genre_dict = {genre['id']: genre['name'] for genre in data_dict['genres']}\n",
        "\n",
        "print(genre_dict)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-DPLdcL1sOi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
